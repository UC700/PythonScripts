{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f336eae-f82b-41de-9081-c6ab091b8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Data Connection Configuration\n",
    "db_params = {\n",
    "    'host': 'nifi1-in.unicommerce.infra',\n",
    "    'port': '5432',\n",
    "    'user': 'uniware_write',\n",
    "    'password': 'uniware@1234',\n",
    "    'database': 'dwh',\n",
    "}\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(**db_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959512f1-c6f2-4d57-afc3-d3ae392a1347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hf/fghb64bn7r5_1hm8k747rzbw0000gn/T/ipykernel_96676/3853672180.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Reading data from DWH\n",
    "\n",
    "query = \"\"\"select tenant,facility,channel_source_code as channel_source,channel_order_created_date as date,\n",
    "count(*) as shipment_count,\n",
    "sum(case when sla_breached_flag then 1 else 0 end) as breached_shipment_count,\n",
    "sum(picking_time) as pt,sum(packing_time) as pat,\n",
    "sum(manifest_time) as mt,sum(dispatch_time) as dt\n",
    "from insights_o2sla where channel_source_code != 'CUSTOM' group by 1,2,3,4\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb954453-d3e0-4b75-897a-b56026639034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aggregate_columns = ['pt', 'pat', 'mt', 'dt']\n",
    "\n",
    "# Function to calculate Z-score\n",
    "def calculate_z_score(series):\n",
    "    z_score = (series - series.mean()) / series.std()\n",
    "    return z_score\n",
    "\n",
    "# Calculate Z-scores for each column within groups at facility and facility-channel level\n",
    "for column in aggregate_columns:\n",
    "    z_score_column = f'{column}_z_score_fac_cha'\n",
    "    df[z_score_column] = df.groupby(['tenant','facility', 'channel_source'])[column].transform(calculate_z_score)\n",
    "\n",
    "for column in aggregate_columns:\n",
    "    z_score_column = f'{column}_z_score_fac'\n",
    "    df[z_score_column] = df.groupby(['tenant','facility'])[column].transform(calculate_z_score)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd8f7418-6e09-4ec5-9ffd-e5d062aecdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Calculating 50th percentile of shipment count for each tenant and then filtering the rest of data\n",
    "quartile_data = df.groupby(['tenant'])['shipment_count'].describe(percentiles=[.5])\n",
    "df = pd.merge(df, quartile_data, how='inner', left_on='tenant', right_on='tenant')\n",
    "df = df[df['shipment_count'] > df['50%']]\n",
    "columns_to_drop = ['count','mean', 'std','min','50%','max']\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe7b765-415f-47af-944e-374e640797b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filtering data basis of SLA Breach Threshold of 0.5 %\n",
    "df['breach_percent'] = 100.00*df['breached_shipment_count'] / df['shipment_count']\n",
    "df = df[df['breach_percent'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f201b7-94f6-4d1c-955c-e02df3bfb14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Picking out max two reasons for SLA Breach on these dates\n",
    "\n",
    "#Facility Level\n",
    "z_score_columns = ['pt_z_score_fac', 'pat_z_score_fac', 'mt_z_score_fac', 'dt_z_score_fac']\n",
    "df['Top2Columns_fac'] = df[z_score_columns].apply(lambda row: row.nlargest(2).index.tolist(), axis=1)\n",
    "df['Top1Reason_fac'], df['Top2Reason_fac'] = zip(*df['Top2Columns_fac'].apply(lambda x: tuple(x[:2])))\n",
    "df.drop('Top2Columns_fac', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Facility Channel Level\n",
    "z_score_columns = ['pt_z_score_fac_cha', 'pat_z_score_fac_cha', 'mt_z_score_fac_cha', 'dt_z_score_fac_cha']\n",
    "df['Top2Columns_fac_cha'] = df[z_score_columns].apply(lambda row: row.nlargest(2).index.tolist(), axis=1)\n",
    "df['Top1Reason_fac_cha'], df['Top2Reason_fac_cha'] = zip(*df['Top2Columns_fac_cha'].apply(lambda x: tuple(x[:2])))\n",
    "df.drop('Top2Columns_fac_cha', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2400f307-8309-4bd2-8f18-54417a5cde42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mapping Column Names to shipment flow\n",
    "\n",
    "mapping_dict = {'pt_z_score_fac': 'Picking Time', 'pat_z_score_fac': 'Packing Time', 'mt_z_score_fac': 'Manifest Time', 'dt_z_score_fac': 'Dispatch Time'}\n",
    "\n",
    "df['Top1Reason_fac'] = df['Top1Reason_fac'].map(mapping_dict)\n",
    "df['Top2Reason_fac'] = df['Top2Reason_fac'].map(mapping_dict)\n",
    "\n",
    "mapping_dict = {'pt_z_score_fac_cha': 'Picking Time', 'pat_z_score_fac_cha': 'Packing Time', 'mt_z_score_fac_cha': 'Manifest Time', 'dt_z_score_fac_cha': 'Dispatch Time'}\n",
    "\n",
    "df['Top1Reason_fac_cha'] = df['Top1Reason_fac_cha'].map(mapping_dict)\n",
    "df['Top2Reason_fac_cha'] = df['Top2Reason_fac_cha'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4923c654-9b7e-49a4-9299-e2b398c92479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping z_score columns\n",
    "df = df.drop(df.filter(like='z_score').columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13314ffd-6219-4e05-84b0-03173ad31394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Inserting Data into DWH\n",
    "\n",
    "# Database connection parameters\n",
    "ddb_params = {\n",
    "    'host': 'nifi1-in.unicommerce.infra',\n",
    "    'port': '5432',\n",
    "    'user': 'uniware_write',\n",
    "    'password': 'uniware%401234',\n",
    "    'database': 'dwh',\n",
    "}\n",
    "\n",
    "engine = create_engine(\"postgresql+psycopg2://uniware_write:uniware%401234@nifi1-in.unicommerce.infra:5432/dwh\")\n",
    "\n",
    "# Specify the name of the PostgreSQL table where you want to insert the data\n",
    "table_name = 'insights_o2sla_anomaly'\n",
    "\n",
    "engine.execute(\"truncate table insights_o2sla_anomaly\")\n",
    "\n",
    "# # Insert the DataFrame into the PostgreSQL table\n",
    "df.to_sql(table_name, engine.connect(),if_exists='replace', index=False)\n",
    "\n",
    "# # Close the SQLAlchemy engine (optional)\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
