{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b082e3b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# ### IMPORTING DEPENDENCIES\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('max_colwidth', None)\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "# nltk.download('stopwords')\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import time\n",
    "from transformers import pipeline\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "\n",
    "# ### DATA ADDITION\n",
    "\n",
    "df = pd.read_csv('/Users/anubhavgupta/Desktop/Return_Reasons_Project/Python/Code/Return_Reasons_test_2024_02_26.csv')\n",
    "\n",
    "df['rpi_count'] = df['count(rpi.sale_order_item_id)']\n",
    "df.drop(columns='count(rpi.sale_order_item_id)', inplace=True)\n",
    "df['short_rr'] = df['return_reason']\n",
    "\n",
    "# ## Removing Null Values\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "source_codes = ['MYNTRAPPMP',\n",
    "                'FLIPKART',\n",
    "                'AMAZON_IN',\n",
    "                'AMAZON_FLEX_API',\n",
    "                'NYKAA_FASHION',\n",
    "                'AJIO_OMNI',\n",
    "                'MEESHO',\n",
    "                'AJIO',\n",
    "                'MYNTRA_B2B',\n",
    "                'SNAPDEAL',\n",
    "                'AMAZON_IN_API',\n",
    "                'LIMEROAD',\n",
    "                'FIRSTCRY',\n",
    "                'TATA_CLIQ',\n",
    "                'NYKAA_COM',\n",
    "                'AMAZON_FBA_IN',\n",
    "                'FLIPKART_FA',\n",
    "                'AMAZON_FBA',\n",
    "                'AMAZON_FLEX',\n",
    "                'AMAZON_EASYSHIP',\n",
    "                'CRED',\n",
    "                'NYKAA',\n",
    "                'JIOMART',\n",
    "                'JIOMART3P']\n",
    "\n",
    "\n",
    "df = df[df['source_code'].isin(source_codes)].reset_index(drop=True)\n",
    "org_df = df.copy()\n",
    "\n",
    "# ### Lowering Each Word \n",
    "return_reason = []\n",
    "for reason in df['short_rr']:\n",
    "    return_reason.append(reason.lower())\n",
    "    \n",
    "df['short_rr'] = return_reason\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"â€™\", \"\"))\n",
    "\n",
    "def clean_txt(text):\n",
    "    return re.sub(r\"[^a-z0-9]\", \" \", text)\n",
    "df['short_rr'] = df['short_rr'].apply(clean_txt)\n",
    "df['short_rr'] = df['short_rr'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "df = df[df['short_rr'] != \"\"]\n",
    "# # ROW REMOVAL 1x\n",
    "# -- CONTAINS SPECFIC WORDS --\n",
    "\n",
    "df = df[~df['short_rr'].str.contains('auto removed')]\n",
    "df = df[~df['short_rr'].str.contains('rtom')]\n",
    "df = df[~df['short_rr'].str.contains('http')]\n",
    "df = df[~df['short_rr'].str.contains('trial')]\n",
    "df = df[~df['short_rr'].str.contains('rtoa')]\n",
    "df = df[~df['short_rr'].str.contains('return reason thanos roh approval flow')]\n",
    "df = df[~df['short_rr'].str.contains('return expected on panel')]\n",
    "df = df[~df['short_rr'].str.contains('test')]\n",
    "df = df[~df['short_rr'].str.contains('myec')]\n",
    "df = df[~df['short_rr'].str.contains('swit')]\n",
    "df = df[~df['short_rr'].str.contains('ajio')]\n",
    "df = df[~df['short_rr'].str.contains('origin')]\n",
    "df = df[~df['short_rr'].str.contains('myn')]\n",
    "df = df[~df['short_rr'].str.contains('limeroad')]\n",
    "df = df[~df['short_rr'].str.contains('flex')]\n",
    "df = df[~df['short_rr'].str.contains('nykaa')]\n",
    "df = df[~df['short_rr'].str.contains('reason not available')]\n",
    "df = df[~df['short_rr'].str.contains('others return reason')]\n",
    "df = df[~df['short_rr'].str.contains(r'^received$')]\n",
    "df = df[~df['short_rr'].str.contains('approved')]\n",
    "df = df[~df['short_rr'].str.contains('pickup')]\n",
    "df = df[~df['short_rr'].str.contains('address')]\n",
    "df = df[~df['short_rr'].str.contains('manually')]\n",
    "df = df[~df['short_rr'].str.contains('myer')]\n",
    "df = df[~df['short_rr'].str.contains('crm')]\n",
    "df = df[~df['short_rr'].str.contains('inventory')]\n",
    "\n",
    "# -- CONTAINS ONLY WORDS --\n",
    "\n",
    "df = df[df['short_rr'] != 'undefined']\n",
    "df = df[df['short_rr'] != 'rto'] \n",
    "df = df[df['short_rr'] != 'courier return'] \n",
    "df = df[df['short_rr'] != 'return'] \n",
    "df = df[df['short_rr'] != 'cr'] \n",
    "df = df[df['short_rr'] != 'customer return']\n",
    "df = df[df['short_rr'] != 'rvp']\n",
    "df = df[df['short_rr'] != 'rtv']\n",
    "\n",
    "# -- CONTAINS CERTAIN PATTERNS -- \n",
    "\n",
    "pattern4 = r'rto \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'rto\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'customer return \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'customer return\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'rtv \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'rtv\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpc\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpc \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpr\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpr \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpp\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpp \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'myep\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'myep \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "word_s = 'rtomanish'\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "word_s = ' ebo '\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "word_s = 'shipment bagout'\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "word_s = 'null null'\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "# -- WORDS REPLACEMENT --\n",
    "\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"recd\", \"received\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"damage\", \"damaged\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"damagedd\", \"damaged\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"colour\", \"color\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"issue\", \"issues\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"issuess\", \"issues\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"qc\", \"quality\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"cancelled\", \"cancel\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"use\", \"used\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"tag \", \"tags \"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"tag \", \"tags \"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"sku\", \"\"))\n",
    "\n",
    "# -- REMOVING WITH ONLY NUMBERS --\n",
    "\n",
    "pattern = r'^[0-9-]+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern, text)  \n",
    "matches = df[df['short_rr'].str.contains(pattern)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern)]\n",
    "\n",
    "# -- REMOVING PATTERNS CONTAINING NUMBERS AND CHARACTER COUNT < 3 --\n",
    "\n",
    "# df['short_rr'] = df['short_rr'].apply(lambda x: ''.join(c for c in x if not c.isdigit()))\n",
    "df = df[df['short_rr'] != '']\n",
    "\n",
    "# -- COMMENT BELOW CODE TO CHECK FOR VALUES < 3 --\n",
    "\n",
    "df['char_count'] = df['short_rr'].apply(lambda x: len(''.join(e for e in x if e.isalnum())))\n",
    "df = df[df['char_count'] > 3]\n",
    "# # REMOVING STOP WORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "custom_stop_words = ['api', 'tcns', 'user', 'com', 'tcnsclothing', 'tcnssupport110', 'radiate', 'org', \n",
    "                     'tcnssupport1','tcnssupport2','tcnssupport3','tcnssupport4','tcnssupport5',\n",
    "                     'tcnssupport8','tcnssupport7','tcnssupport6','tcnssupport9', 'seller', 'tcnssupportt3',\n",
    "                     'technotask co','technotask', 'co', 'rto', 'dto', 'cocoblue', 'cx', \n",
    "                     'crmanish', 'tcnssupport', 'fmpr', 'myep', 'amz', 'pg', 'rvp', 'rtv', 'fmpp', 'dto',\n",
    "                     'cr', 'app', 'channel', 'name', 'mesh', 'myntra','api', 'tcns', 'user', 'com', 'tcnsclothing', 'tcnssupport110', 'radiate', 'org', \n",
    "                     'tcnssupport1','tcnssupport2','tcnssupport3','tcnssupport4','tcnssupport5',\n",
    "                     'tcnssupport8','tcnssupport7','tcnssupport6','tcnssupport9', 'seller', 'tcnssupportt3',\n",
    "                     'technotask co','technotask', 'co', 'rto', 'dto', 'given','cocoblue', 'cx', 'customer', \n",
    "                     'crmanish', 'tcnssupport', 'fmpr', 'myep', 'amz', 'pg', 'rvp', 'rtv', 'fmpp', 'dto',\n",
    "                     'cr', 'app', 'channel', 'name', 'mesh', 'flipkart', 'amazon', 'return',\n",
    "                     'generic', 'claim','buyer', 'courier']\n",
    "\n",
    "stop_words = set(stopwords.words('german'))\n",
    "stop_words.update(custom_stop_words)\n",
    "\n",
    "# -- EXCLUDING CERTAIN STOPWORDS --\n",
    "\n",
    "#but added\n",
    "word_to_exclude = \"doesn\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"not\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"doesnt\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"no\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"dont\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"does\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"the\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"didnt\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"what\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"did\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "word_to_exclude = \"didn\"\n",
    "stop_words = stop_words.difference({word_to_exclude})\n",
    "stop_words.update(stop_words)\n",
    "\n",
    "\n",
    "final_reason = []\n",
    "\n",
    "for string in df['short_rr']:\n",
    "    words = word_tokenize(string)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    filtered_string = ' '.join(filtered_words)\n",
    "    final_reason.append(filtered_string)\n",
    "\n",
    "    \n",
    "df['short_rr'] = final_reason\n",
    "df = df[['source_code', 'return_reason', 'short_rr' ,'rpi_count']]\n",
    "df = df[df['short_rr'] != '']\n",
    "# df['char_count'] = df['short_rr'].apply(lambda x: len(''.join(e for e in x if e.isalnum())))\n",
    "# df = df[df['char_count'] > 3]\n",
    "# ## WORD CORRECTION\n",
    "corrected_words = ['misshipment', 'return', 'customer', 'delivered','panel', 'flipkart','mismatch', \n",
    "                   'different', 'wrong', 'comfort', 'level', 'received', 'confirmed', 'claim', 'missing', 'product', \n",
    "                   'quality', 'cancel', 'buyer', 'courier', 'defective', 'damaged','damage']\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "replaced_words = defaultdict(list)\n",
    "\n",
    "def replace_words(text, corrected_words, threshold=0.8):\n",
    "    corrected_string = []\n",
    "    for word in text.split():\n",
    "        max_similarity = max(textdistance.jaccard.normalized_similarity(word, cw) for cw in corrected_words)\n",
    "        if max_similarity >= threshold:\n",
    "            max_word = max(corrected_words, key=lambda cw: textdistance.jaccard.normalized_similarity(word, cw))\n",
    "            if word != max_word:\n",
    "                replaced_words[word].append(max_word)\n",
    "            corrected_string.append(max_word)\n",
    "        else:\n",
    "            corrected_string.append(word)\n",
    "    return ' '.join(corrected_string)\n",
    "\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: replace_words(x, corrected_words, threshold=0.75))\n",
    "\n",
    "\n",
    "# row removal x2\n",
    "word_to_search = 'test'\n",
    "df = df[~df['short_rr'].str.contains(word_to_search)]\n",
    "\n",
    "word_to_search = 'myer'\n",
    "df = df[~df['short_rr'].str.contains(word_to_search)]\n",
    "\n",
    "word_to_search = 'crm'\n",
    "df = df[~df['short_rr'].str.contains(word_to_search)]\n",
    "\n",
    "word_to_search = 'inventory'\n",
    "df = df[~df['short_rr'].str.contains(word_to_search)]\n",
    "\n",
    "word_to_search = 'myec'\n",
    "df = df[~df['short_rr'].str.contains(word_to_search)]\n",
    "\n",
    "word_to_search = 'return expected on panel'\n",
    "df = df[~df['short_rr'].str.contains(word_to_search)]\n",
    "\n",
    "df = df[df['short_rr'] != 'undefined']\n",
    "df = df[df['short_rr'] != 'rto'] \n",
    "df = df[df['short_rr'] != 'courier return'] \n",
    "df = df[df['short_rr'] != 'return'] \n",
    "df = df[df['short_rr'] != 'cr'] \n",
    "df = df[df['short_rr'] != 'customer return']\n",
    "df = df[df['short_rr'] != 'rvp']\n",
    "df = df[df['short_rr'] != 'rtv']\n",
    "# pattern = r'rto\\s+(?:' + '|'.join(return_reasons) + r')\\b'\n",
    "# df = df[~df['short_rr'].str.contains(pattern, regex=True)]\n",
    "## space w/o space\n",
    "\n",
    "pattern4 = 'ajio'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'rto \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'rto\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'customer return \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'customer return\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "matches = df[df['short_rr'].str.contains(pattern4)]['short_rr'].tolist()\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'rtv \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'rtv\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpc\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpc \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpr\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpr \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpp\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'fmpp \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "# word_to_search = \"dto\"\n",
    "# df = df[~df['short_rr'].str.contains(word_to_search)]\n",
    "\n",
    "## DTO stopword 'amz pg' , 'amz pg app'\n",
    "# dto, rtv, fmpc, myec,\n",
    "\n",
    "pattern4 = r'myep\\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "pattern4 = r'myep \\d+$'\n",
    "for text in df['short_rr']:\n",
    "    matches = re.findall(pattern4, text)\n",
    "df = df[~df['short_rr'].str.contains(pattern4)]\n",
    "\n",
    "word_s = 'rtomanish'\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "word_s = ' ebo '\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "# word_s = ' rt '\n",
    "# df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "word_s = 'shipment bagout'\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "word_s = 'null null'\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "word_s = 'bag id'\n",
    "df = df[~df['short_rr'].str.contains(word_s)]\n",
    "\n",
    "df = df[~df['short_rr'].str.contains('origin')]\n",
    "\n",
    "df = df[~df['short_rr'].str.contains('myn')]\n",
    "df = df[~df['short_rr'].str.contains('limeroad')]\n",
    "df = df[~df['short_rr'].str.contains('flex')]\n",
    "df = df[~df['short_rr'].str.contains('nykaa')]\n",
    "df = df[~df['short_rr'].str.contains('reason not available')]\n",
    "df = df[~df['short_rr'].str.contains('others return reason')]\n",
    "df = df[~df['short_rr'].str.contains(r'^received$')]\n",
    "df = df[~df['short_rr'].str.contains('approved')]\n",
    "df = df[~df['short_rr'].str.contains('pickup')]\n",
    "df = df[~df['short_rr'].str.contains('address')]\n",
    "df = df[~df['short_rr'].str.contains('manually')]\n",
    "df = df[~df['short_rr'].str.contains('rto')]\n",
    "\n",
    "\n",
    "# df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"customer\", \"\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"recd\", \"received\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"damage\", \"damaged\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"damagedd\", \"damaged\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"colour\", \"color\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"issue\", \"issues\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"issuess\", \"issues\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"qc\", \"quality\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"undefined\", \"\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"cancelled\", \"cancel\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"use\", \"used\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"tag \", \"tags \"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"defective\", \"damaged\"))\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: x.replace(\"item\", \"product\"))\n",
    "\n",
    "pattern = r'^[0-9-]+$'\n",
    "df = df[~df['short_rr'].str.contains(pattern)]\n",
    "df['short_rr'] = df['short_rr'].apply(lambda x: ''.join(c for c in x if not c.isdigit()))\n",
    "df = df[df['short_rr'] != '']\n",
    "df['char_count'] = df['short_rr'].apply(lambda x: len(''.join(e for e in x if e.isalnum())))\n",
    "df = df[df['char_count'] > 3]\n",
    "\n",
    "\n",
    "def remove_extra_characters(word):\n",
    "    return re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "df['short_rr'] = df['short_rr'].apply(remove_extra_characters)\n",
    "\n",
    "grouped = df.groupby(by='short_rr')['rpi_count'].sum().sort_values(ascending=False)\n",
    "grouped = pd.DataFrame(grouped)\n",
    "grouped = grouped[grouped > 10]\n",
    "grouped.dropna(inplace=True)\n",
    "grouped.reset_index(inplace=True)\n",
    "# df.groupby(by='short_rr')['rpi_count'].sum().sort_values(ascending=False).to_excel(\"/Users/anubhavgupta/Desktop/Return_Reasons_Project/Excels/Cleaned Data/test_data_after_algo.xlsx\")\n",
    "# grouped.to_excel(\"/Users/anubhavgupta/Desktop/Return_Reasons_Project/Excels/Final Algorithm/Unclassified Data/2022.xlsx\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ff17ba",
   "metadata": {},
   "source": [
    "# ZERO SHOT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c1228fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('/Users/anubhavgupta/Desktop/Return_Reasons_Project/Excels/Cleaned Data/final_dfv4.xlsx')\n",
    "# full classified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f7bb715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"/Users/anubhavgupta/Desktop/Return_Reasons_Project/Excels/Final Algorithm/Unclassified Data/2022.xlsx\")\n",
    "subclasses = ['fit issue',\n",
    " 'small size',\n",
    " 'large size',\n",
    " 'did not like product',\n",
    " 'product image better',\n",
    " 'not required anymore',\n",
    " 'wrong product recevied',\n",
    " 'damaged product',\n",
    " 'material issues',\n",
    " 'delivery issue', \n",
    " 'product missing',\n",
    " 'ordered incorrectly',\n",
    " 'found better price',\n",
    " 'price related',\n",
    " 'unsatisfactory product']\n",
    "\n",
    "\n",
    "\n",
    "candidate_labels = subclasses\n",
    "def classify_return_reasons(df, classifier, candidate_labels):\n",
    "    classifications = []\n",
    "    for return_reason in df['short_rr']:\n",
    "        classification = classifier(return_reason, candidate_labels, multi_label=False)\n",
    "        highest_label = max(classification['scores'])\n",
    "        highest_label_idx = classification['scores'].index(highest_label)\n",
    "        highest_label_name = classification['labels'][highest_label_idx]\n",
    "        classifications.append(highest_label_name)\n",
    "    df['classification'] = classifications\n",
    "    return df\n",
    "\n",
    "df = classify_return_reasons(df, classifier, candidate_labels)\n",
    "# (classified_df[['short_rr', 'classification','rpi_count']])\n",
    "# df.to_excel('/Users/anubhavgupta/Desktop/Return_Reasons_Project/Excels/Final Algorithm/Classified Data/2022.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
